from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import time

# WebDriverのパスを設定
driver_path = 'C:\\Users\\USER\\Desktop\\chromedriver.exe'

# サービスオブジェクトを作成してWebDriverに渡す
service = Service(driver_path)
driver = webdriver.Chrome(service=service)

# 指定されたURLにアクセス
url = 'https://www.hanacupid.or.jp/stores/details/03101'
driver.get(url)

# ページの読み込みを待機
try:
    # 'data' クラスの <div> が見つかるまで最大10秒待機
    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'data')))
    print("Page loaded successfully.")
except:
    print("Error: The 'data' div could not be found.")
    driver.quit()
    exit()

# BeautifulSoupを使用してページソースを解析
soup = BeautifulSoup(driver.page_source, 'html.parser')

# 'data' クラスの <div> を取得
data_div = soup.find('div', class_='data')

if data_div is not None:
    # <dt> と <dd> のペアを取得して出力
    for dt, dd in zip(data_div.find_all('dt'), data_div.find_all('dd')):
        print(f"{dt.text.strip()}: {dd.text.strip()}")
else:
    print("Error: 'data' div was not found in the page source.")

# ウェブドライバーを終了
driver.quit()
#2024_08_14お花屋さんのスクレイピングで、Webサイトで店名を出して、ターミナルに出力するものOK
